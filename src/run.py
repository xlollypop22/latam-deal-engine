from __future__ import annotations

import os
import re
from datetime import datetime, timezone
import yaml

from .config import load_config
from .ingest import parse_feed
from .extract import fetch_article_text
from .groq_ai import groq_extract
from .score import compute_score
from .storage import (
    init_db,
    load_state,
    save_state,
    is_seen,
    mark_seen,
    insert_deal,
)
from .telegram import send_message, esc
from .utils import utc_now_iso, clamp, normalize_url


def load_sources(path: str):
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    return data.get("sources", [])


# ----------------- Filters -----------------

def parse_iso_dt(s: str | None) -> datetime | None:
    if not s:
        return None
    try:
        # Python 3.11: fromisoformat –ø–æ–Ω–∏–º–∞–µ—Ç "+00:00"
        return datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        return None


def extract_year_from_url(url: str) -> int | None:
    # TechCrunch: /2025/03/27/...
    m = re.search(r"/(20\d{2})/", url or "")
    if not m:
        return None
    try:
        return int(m.group(1))
    except Exception:
        return None


def is_allowed_year(published_at_iso: str | None, url: str, min_year: int) -> bool:
    dt = parse_iso_dt(published_at_iso)
    if dt:
        return dt.year >= min_year
    y = extract_year_from_url(url)
    if y is not None:
        return y >= min_year
    # –µ—Å–ª–∏ –≥–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ–ª—å–∑—è ‚Äî —Å—á–∏—Ç–∞–µ–º –ù–ï –æ–∫, –∫–æ–≥–¥–∞ strict
    return False


def fmt_amount(amount):
    if not isinstance(amount, (int, float)) or amount <= 0:
        return None
    if amount >= 1_000_000:
        return f"${amount/1_000_000:.1f}M"
    if amount >= 1_000:
        return f"${amount/1_000:.0f}K"
    return f"${amount:.0f}"


def join_bullets(items, max_n=4):
    items = [x.strip() for x in (items or []) if x and x.strip()]
    return items[:max_n]


# ----------------- Formatting (your desired style) -----------------

LINK_ICON = os.getenv("LINK_ICON", "‚Üó").strip() or "‚Üó"


def format_signal_ru(source: str, title: str, url: str, deal: dict, score: int) -> str:
    country = deal.get("country") or "LATAM"
    company = deal.get("company") or "–ö–æ–º–ø–∞–Ω–∏—è"
    stage = deal.get("stage") or "Unknown"
    bm = deal.get("business_model") or "Unknown"
    sector = deal.get("sector") or "unknown"

    amount_str = fmt_amount(deal.get("amount_usd")) or "‚Äî"
    investors = deal.get("investors") or []
    ru_one_line = deal.get("ru_one_line") or ""

    inv_str = ", ".join(investors[:4])

    # —Å—Å—ã–ª–∫–∞ –≤ –∏–∫–æ–Ω–∫—É (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞)
    link = f"{LINK_ICON} {esc(url)}"

    lines = []
    lines.append(f"üì° –°–¥–µ–ª–∫–∞ / —Å–∏–≥–Ω–∞–ª | {esc(country)}")
    lines.append(f"–ö–æ–º–ø–∞–Ω–∏—è: {esc(company)}")
    lines.append(f"{esc(clamp(title, 220))}")

    lines.append(f"–†–∞—É–Ω–¥: {esc(stage)} | –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏: {esc(amount_str)} | –ú–æ–¥–µ–ª—å: {esc(bm)}")
    lines.append(f"–°–µ–∫—Ç–æ—Ä: {esc(sector)} | –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞: {score}/100")

    if ru_one_line:
        lines.append(f"üß† {esc(clamp(ru_one_line, 220))}")

    if inv_str:
        lines.append(f"üíº –ò–Ω–≤–µ—Å—Ç–æ—Ä—ã: {esc(inv_str)}")

    lines.append(link)

    # —É–±—Ä–∞–ª–∏ "–ò—Å—Ç–æ—á–Ω–∏–∫" –∏ "–°–∏–≥–Ω–∞–ª—ã" ‚Äî –∫–∞–∫ —Ç—ã —Ö–æ—Ç–µ–ª
    return "\n".join(lines)


def format_note_ru(deal: dict, score: int, reasons: list[str]) -> str:
    why = join_bullets(deal.get("ru_why_important"), 4)

    # "–ö–∞–∫ –∑–∞–π—Ç–∏ –≤ —Å–¥–µ–ª–∫—É" ‚Üí "–ü–ª—é—Å—ã –ø—Ä–æ–µ–∫—Ç–∞"
    pros = join_bullets(deal.get("ru_deal_angles"), 4)

    watch = join_bullets(deal.get("ru_watchouts"), 3)

    lines = []
    lines.append(f"üìù –ö–æ—Ä–æ—Ç–∫–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (–æ—Ü–µ–Ω–∫–∞ {score}/100)")

    if reasons:
        lines.append(f"‚öôÔ∏è –°–∫–æ—Ä–∏–Ω–≥: {esc(', '.join(reasons[:8]))}")

    if why:
        lines.append("\n–ü–æ—á–µ–º—É –ø—Ä–æ–µ–∫—Ç –≤–∞–∂–µ–Ω")
        for b in why:
            lines.append(f"‚Ä¢ {esc(clamp(b, 160))}")

    if pros:
        lines.append("\n–ü–ª—é—Å—ã –ø—Ä–æ–µ–∫—Ç–∞")
        for b in pros:
            lines.append(f"‚Ä¢ {esc(clamp(b, 160))}")

    if watch:
        lines.append("\n–†–∏—Å–∫–∏ / –æ–≥–æ–≤–æ—Ä–∫–∏")
        for b in watch:
            lines.append(f"‚Ä¢ {esc(clamp(b, 160))}")

    return "\n".join(lines)


# ----------------- MAIN -----------------

def main():
    cfg = load_config()
    init_db(cfg.db_path)

    state = load_state(cfg.state_path)
    sources = load_sources(cfg.sources_path)
    if not sources:
        raise RuntimeError("No sources found in sources.yaml")

    # env controls
    max_posts = int(os.getenv("MAX_POSTS_PER_RUN", "2"))
    min_year = int(os.getenv("MIN_PUBLISHED_YEAR", "2026"))
    strict_year = os.getenv("YEAR_FILTER_STRICT", "1") == "1"

    # ‚Äú–Ω–æ–≤–æ–µ‚Äù —Å—á–∏—Ç–∞–µ–º –æ—Ç last_run_utc
    last_run_dt = parse_iso_dt(state.get("last_run_utc"))
    if last_run_dt is None:
        # –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫/–Ω–µ—Ç –¥–∞—Ç—ã ‚Äî –±–µ—Ä—ë–º –æ—á–µ–Ω—å —Å—Ç–∞—Ä—É—é —Ç–æ—á–∫—É
        last_run_dt = datetime(2000, 1, 1, tzinfo=timezone.utc)

    posted = 0
    processed_new = 0

    # debug counters
    skipped_seen = 0
    skipped_not_newer_than_last_run = 0
    skipped_year = 0

    for s in sources:
        name = s["name"]
        feed_url = s["url"]

        items = parse_feed(name, feed_url)

        for it in items:
            u = normalize_url(it.url)

            if is_seen(state, u, it.guid):
                skipped_seen += 1
                continue

            # —Ñ–∏–ª—å—Ç—Ä ‚Äú–Ω–æ–≤–µ–µ –ø—Ä–æ—à–ª–æ–≥–æ –∑–∞–ø—É—Å–∫–∞‚Äù
            it_dt = parse_iso_dt(it.published_at)
            if it_dt and it_dt <= last_run_dt:
                skipped_not_newer_than_last_run += 1
                continue

            # —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É (2026+)
            if strict_year and not is_allowed_year(it.published_at, u, min_year):
                skipped_year += 1
                continue

            processed_new += 1

            # 1) extract text
            try:
                text = fetch_article_text(u)
            except Exception:
                text = ""

            # 2) AI extract + RU analytics
            try:
                deal_obj = groq_extract(
                    api_key=cfg.groq_api_key,
                    model=cfg.groq_model,
                    title=it.title,
                    url=u,
                    source=it.source,
                    text=text,
                    fallback_summary=it.summary,
                )
            except Exception as e:
                print(f"[GROQ ERROR] {u} | {e}")
                # –ù–ï mark_seen ‚Äî –ø—É—Å—Ç—å –ø–æ–ø—Ä–æ–±—É–µ—Ç —Å–Ω–æ–≤–∞
                continue

            deal = deal_obj.model_dump()

            # 3) scoring
            sr = compute_score(
                country=deal.get("country"),
                stage=deal.get("stage"),
                sector=deal.get("sector"),
                business_model=deal.get("business_model"),
                signals=deal.get("signals") or [],
                investors=deal.get("investors") or [],
            )

            # 4) Post #1 (signal)
            signal_text = format_signal_ru(it.source, it.title, u, deal, sr.score)
            try:
                msg_id = send_message(cfg.telegram_bot_token, cfg.telegram_channel_id, signal_text)
            except Exception as e:
                print(f"[TG ERROR] {u} | {e}")
                continue

            # 5) Post #2 (note) as reply
            note_text = format_note_ru(deal, sr.score, sr.reasons)
            try:
                send_message(
                    cfg.telegram_bot_token,
                    cfg.telegram_channel_id,
                    note_text,
                    reply_to_message_id=msg_id,
                )
            except Exception:
                pass

            # 6) store
            record = {
                "created_at_utc": utc_now_iso(),
                "source": it.source,
                "title": it.title,
                "url": u,
                "guid": it.guid,
                "published_at": it.published_at,
                "company": deal.get("company"),
                "country": deal.get("country"),
                "stage": deal.get("stage"),
                "amount_usd": deal.get("amount_usd"),
                "investors": ",".join(deal.get("investors") or []),
                "sector": deal.get("sector"),
                "business_model": deal.get("business_model"),
                "signals": ",".join(deal.get("signals") or []),
                "one_line": deal.get("ru_one_line"),
                "confidence": deal.get("confidence"),
                "deal_score": sr.score,
                "score_reasons": ",".join(sr.reasons),
            }
            insert_deal(cfg.db_path, record)

            # 7) mark seen
            mark_seen(state, u, it.guid)
            posted += 1

            if posted >= max_posts:
                break

        if posted >= max_posts:
            break

    save_state(cfg.state_path, state)

    print(
        "Processed new items: "
        f"{processed_new}, Posted deals: {posted} | "
        f"skipped_seen={skipped_seen}, "
        f"skipped_old={skipped_not_newer_than_last_run}, "
        f"skipped_year={skipped_year}"
    )


if __name__ == "__main__":
    main()
